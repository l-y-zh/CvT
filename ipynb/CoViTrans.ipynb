{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2bd1fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "import paddle.nn.functional as func\n",
    "\n",
    "from paddle import  nn\n",
    "from paddle.nn.initializer import TruncatedNormal, Constant\n",
    "\n",
    "'''\n",
    "#### Set truncated Gaussian distribution ####\n",
    "'''\n",
    "truncated_normal_initial = TruncatedNormal(std=.02)\n",
    "zero = Constant(value=0.)\n",
    "one = Constant(value=1.)\n",
    "\n",
    "\n",
    "## do nothing\n",
    "class Identity(nn.Layer):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(Identity, self).__init__()\n",
    "        \n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de3e64d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#### Reshape the tensor while taking convolutional token embedding ####\n",
    "'''\n",
    "class Reshape(nn.Layer):\n",
    "    def __init__(self,string,h,w):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.string = string\n",
    "        self.h = h\n",
    "        self.w = w\n",
    "        \n",
    "        \n",
    "    def forward(self,inputs):\n",
    "\n",
    "        if self.string == 'b c h w -> b (h w) c':\n",
    "            N, C, H, W = inputs.shape\n",
    "            x = paddle.reshape(x=inputs, shape=(N, -1, self.h*self.w)).transpose((0, 2, 1))\n",
    "\n",
    "        if self.string == 'b (h w) c -> b c h w':\n",
    "            N, _, C = inputs.shape\n",
    "            x = paddle.reshape(x=inputs,shape=(N, self.h, self.w, -1)).transpose((0, 3, 1, 2))\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f021fbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#### Depth separable convolutional layer ####\n",
    "'''\n",
    "class DepSepConv2D(nn.Layer):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1):\n",
    "        \n",
    "        super(DepSepConv2D, self).__init__()\n",
    "\n",
    "        #depthwise Conv2D\n",
    "        self.depthwise = nn.Conv2D(in_channels=in_channels, out_channels=in_channels, kernel_size=kernel_size, \n",
    "                                   stride=stride, padding=padding, dilation=dilation, groups=in_channels)\n",
    "\n",
    "        self.bn = nn.BatchNorm(num_channels=in_channels)\n",
    "\n",
    "        #pointwise Conv2D\n",
    "        self.pointwise = nn.Conv2D(in_channels=in_channels, out_channels=out_channels, \n",
    "                                   kernel_size=1, stride=1, padding=0, dilation=1, groups=1)\n",
    "\n",
    "        \n",
    "    def forward(self,input):\n",
    "        x = self.depthwise(input)\n",
    "        x = self.bn(x)\n",
    "        x = self.pointwise(x)\n",
    "        \n",
    "        return  x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94793490",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#### Reshape the tensor in the module of transformer if necessary. ####\n",
    "'''\n",
    "def reshape_in_transformer(x, string, l=0, w=0, h=0, **kwargs):\n",
    "    b, n , c = x.shape[:3]\n",
    "\n",
    "    if string == 'b n (h d) -> b h n d':\n",
    "        x = paddle.reshape(x=x,shape=(b, n, h, -1)).transpose((0, 2, 1, 3))\n",
    "\n",
    "    if string == 'b (l w) n -> b n l w':\n",
    "        x = paddle.reshape(x=x,shape=(b, l, w, -1)).transpose((0, 3, 1, 2))\n",
    "        \n",
    "    if string == 'b (h d) l w -> b h (l w) d':\n",
    "        b, h_d, l, w = x.shape\n",
    "        x = paddle.reshape(x=x,shape=(b, h, l*w, -1))\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97a29c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#### Multi-Heat Attention ####\n",
    "#### Here we use Depth Separable Convolutional Layer defined above, ####\n",
    "#### insteading of Linear Project in ViT. ####\n",
    "'''\n",
    "class ConAtt(nn.Layer):\n",
    "    def __init__(self, dim,img_size, heads=8, dim_head=64, \n",
    "                 kernel_size=3, q_stride=1, k_stride=1, v_stride=1, \n",
    "                 dropout=0., last_stage=False):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.last_stage = last_stage\n",
    "        self.img_size = img_size\n",
    "        inner_dim = dim_head * heads\n",
    "        project_out = not (heads==1 and dim_head==dim)\n",
    "\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** (-0.5)\n",
    "        pad = (kernel_size - q_stride) // 2\n",
    "        \n",
    "        ## using Depth Separable Convolution to reduce the parameters.\n",
    "        self.to_q = DepSepConv2D(in_channels=dim, out_channels=inner_dim, \n",
    "                                 kernel_size=kernel_size, stride=q_stride, padding=pad)\n",
    "        self.to_k = DepSepConv2D(in_channels=dim, out_channels=inner_dim, \n",
    "                                 kernel_size=kernel_size, stride=k_stride, padding=pad)\n",
    "        self.to_v = DepSepConv2D(in_channels=dim, out_channels=inner_dim, \n",
    "                                 kernel_size=kernel_size, stride=v_stride, padding=pad)\n",
    "\n",
    "        self.out = nn.Sequential(nn.Linear(in_features=inner_dim, out_features=dim), \n",
    "                                 nn.Dropout(dropout)) if project_out else Identity()\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        ## x shape: ([1, 3136, 64])\n",
    "        b, n, c, h = *x.shape, self.heads\n",
    "        \n",
    "        if self.last_stage:\n",
    "            cls_token = x[:, 0]\n",
    "            x = x[:, 1:]\n",
    "            ## class token for classification\n",
    "            cls_token = reshape_in_transformer(x=paddle.unsqueeze(cls_token, axis=1), \n",
    "                                               string='b n (h d) -> b h n d', h=h)\n",
    "\n",
    "        ## x shape: ([1, 64, 56, 56])\n",
    "        x = reshape_in_transformer(x=x, string='b (l w) n -> b n l w',\n",
    "                                   l=self.img_size, w=self.img_size)\n",
    "\n",
    "        ## q shape: ([1, 64, 56, 56])\n",
    "        q = self.to_q(x) \n",
    "        \n",
    "        ## q shape: ([1, 1, 3136, 64])\n",
    "        q = reshape_in_transformer(x=q, string='b (h d) l w -> b h (l w) d', h=h)\n",
    "\n",
    "        k = self.to_k(x)\n",
    "        k = reshape_in_transformer(x=k, string='b (h d) l w -> b h (l w) d', h=h)\n",
    "\n",
    "        v = self.to_v(x)\n",
    "        v = reshape_in_transformer(x=v, string='b (h d) l w -> b h (l w) d', h=h)\n",
    "\n",
    "        if self.last_stage:\n",
    "            q = paddle.concat((cls_token, q), axis=2)\n",
    "            v = paddle.concat((cls_token, v), axis=2)\n",
    "            k = paddle.concat((cls_token, k), axis=2)\n",
    "\n",
    "\n",
    "        ## calculate final attention\n",
    "        attention = (q.matmul(k.transpose((0,1,3,2)))) * self.scale\n",
    "\n",
    "        ## take softmax\n",
    "        attention = func.softmax(attention, axis=-1)\n",
    "\n",
    "        ## matmul v\n",
    "        out = (attention.matmul(v)).transpose((0, 2, 1, 3)).reshape((b, n, c))\n",
    "\n",
    "        #linear project\n",
    "        out = self.out(out)\n",
    "        \n",
    "        return  out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2960cc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#### Residual skip connection in transformer module ####\n",
    "'''\n",
    "class Residual(nn.Layer):\n",
    "    def __init__(self, fn):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.fn = fn\n",
    "\n",
    "        \n",
    "    def forward(self, inputs, **kwargs):\n",
    "        x = self.fn(inputs, **kwargs)\n",
    "        \n",
    "        return (x + inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4aeb4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#### Add Layer Normalization ####\n",
    "'''\n",
    "class LayerNorm(nn.Layer):\n",
    "    def __init__(self, dim, fn):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.fn = fn\n",
    "        \n",
    "        \n",
    "    def forward(self, inputs, **kwargs):\n",
    "        \n",
    "        return self.fn(self.norm(inputs), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d44019c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#### MLP Layer ####\n",
    "'''\n",
    "class FeedForward(nn.Layer):\n",
    "    def __init__(self, dim, hidden_dim, dropout=0.):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.neu_net = nn.Sequential(nn.Linear(in_features=dim, out_features=hidden_dim),\n",
    "                                     nn.GELU(),\n",
    "                                     nn.Dropout(dropout),\n",
    "                                     nn.Linear(in_features=hidden_dim, out_features=dim),\n",
    "                                     nn.Dropout(dropout))\n",
    "        \n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        \n",
    "        return self.neu_net(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed9e8c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#### Defination of Transformer Layer ####\n",
    "'''\n",
    "class Transformer(nn.Layer):\n",
    "    def __init__(self, dim, img_size, depth, heads, dim_head, mlp_dim, dropout=0., last_stage=False):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers = nn.LayerList([nn.LayerList(\n",
    "            [LayerNorm(dim=dim, fn=ConAtt(dim,img_size, heads=heads, dim_head=dim_head, \n",
    "                                          dropout=dropout, last_stage=last_stage)),\n",
    "             LayerNorm(dim=dim, fn=FeedForward(dim=dim, hidden_dim=mlp_dim, dropout=dropout))\n",
    "            ]) for _ in range(depth)\n",
    "        ])\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for attention, feed_forward in self.layers:\n",
    "            x = attention(x) + x\n",
    "            x = feed_forward(x) + x\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60c706f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#### Final CvT ####\n",
    "'''\n",
    "class CvT(nn.Layer):\n",
    "    def __init__(self, image_size, in_channels, num_classes, \n",
    "                 dim=64, kernels=[7, 3, 3], strides=[4, 2, 2],\n",
    "                 heads=[1, 3, 6], depth=[1, 2, 10], \n",
    "                 pool='cls', dropout=0., emb_dropout=0., scale_dim=4):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        ## pool type must be either cls or mean pooling\n",
    "        self.pool = pool\n",
    "        self.dim = dim\n",
    "        \n",
    "        ## stage 1\n",
    "        self.stage1_conv_embed = nn.Sequential(nn.Conv2D(in_channels=in_channels, out_channels=dim, \n",
    "                                                         kernel_size=kernels[0], stride=strides[0], \n",
    "                                                         padding=2),\n",
    "                                               Reshape('b c h w -> b (h w) c', \n",
    "                                                       h=image_size//4, w=image_size//4),\n",
    "                                               nn.LayerNorm(dim))\n",
    "        \n",
    "        self.stage1_transformer = nn.Sequential(Transformer(dim=dim, img_size=image_size//4, \n",
    "                                                            depth=depth[0], heads=heads[0], \n",
    "                                                            dim_head=self.dim, mlp_dim=dim*scale_dim, \n",
    "                                                            dropout=dropout), \n",
    "                                                Reshape(string='b (h w) c -> b c h w', \n",
    "                                                        h=image_size//4, w=image_size//4))\n",
    "\n",
    "        ## stage 2\n",
    "        in_channels = dim\n",
    "        scale = heads[1] // heads[0]\n",
    "        dim = scale * dim\n",
    "        \n",
    "        self.stage2_conv_embed = nn.Sequential(nn.Conv2D(in_channels=in_channels, out_channels=dim, \n",
    "                                                         kernel_size=kernels[1], stride=strides[1], \n",
    "                                                         padding=1),\n",
    "                                               Reshape(string='b c h w -> b (h w) c',\n",
    "                                                        h=image_size//8, w=image_size//8), \n",
    "                                               nn.LayerNorm(dim))\n",
    "        \n",
    "        self.stage2_transformer = nn.Sequential(Transformer(dim=dim, img_size=image_size//8, \n",
    "                                                            depth=depth[1], heads=heads[1], \n",
    "                                                            dim_head=self.dim, mlp_dim=dim*scale_dim, \n",
    "                                                            dropout=dropout), \n",
    "                                                Reshape(string='b (h w) c -> b c h w', \n",
    "                                                         h=image_size//8, w=image_size//8))\n",
    "\n",
    "        ## stage 3\n",
    "        in_channels = dim\n",
    "        scale = heads[2] // heads[1]\n",
    "        dim = scale * dim\n",
    "        \n",
    "        self.stage3_conv_embed = nn.Sequential(nn.Conv2D(in_channels=in_channels, out_channels=dim, \n",
    "                                                         kernel_size=kernels[2], stride=strides[2], \n",
    "                                                         padding=1),\n",
    "                                               Reshape(string='b c h w -> b (h w) c', \n",
    "                                                        h=image_size//16, w=image_size//16),\n",
    "                                               nn.LayerNorm(dim))\n",
    "        \n",
    "        self.stage3_transformer = nn.Sequential(Transformer(dim=dim, img_size=image_size//16, \n",
    "                                                            depth=depth[2], heads=heads[2], \n",
    "                                                            dim_head=self.dim, mlp_dim=dim*scale_dim, \n",
    "                                                            dropout=dropout, last_stage=True))\n",
    "\n",
    "        ## class token\n",
    "        self.cls_token = self.create_parameter(shape=(1, 1, dim), default_initializer=zero)\n",
    "        \n",
    "        self.add_parameter(\"cls_token\", self.cls_token)\n",
    "\n",
    "        self.dropout_large = nn.Dropout(emb_dropout)\n",
    "\n",
    "        self.mlp_head = nn.Sequential(nn.LayerNorm(dim), nn.Linear(in_features=dim, \n",
    "                                                                   out_features=num_classes))\n",
    "\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.stage1_conv_embed(inputs)\n",
    "        x = self.stage1_transformer(x)\n",
    "\n",
    "        x = self.stage2_conv_embed(x)\n",
    "        x = self.stage2_transformer(x)\n",
    "\n",
    "        x = self.stage3_conv_embed(x)\n",
    "\n",
    "        b, n, _ = x.shape\n",
    "        \n",
    "        cls_tokens = self.cls_token.expand((b, -1, -1))\n",
    "        \n",
    "        x = paddle.concat((cls_tokens, x), axis=1)\n",
    "\n",
    "        x = self.stage3_transformer(x)\n",
    "\n",
    "        x = paddle.mean(x, axis=1) if self.pool == 'mean' else x[:,0]\n",
    "\n",
    "        x = self.mlp_head(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37969b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of output: [1, 4]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "###############\n",
    "#### Check ####\n",
    "###############\n",
    "'''\n",
    "def main():\n",
    "    model = CvT(image_size=512, in_channels=1, num_classes=4)\n",
    "\n",
    "#     paddle.summary(model,input_size=(1, 1, 512, 512))\n",
    "\n",
    "    out = model(paddle.randn(shape=(1, 1, 512, 512)))\n",
    "\n",
    "    print(f'Shape of output: {out.shape}')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5034b967",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
