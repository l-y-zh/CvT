{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b8ad360",
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "import paddle.nn.functional as func\n",
    "\n",
    "from paddle import  nn\n",
    "from paddle.nn.initializer import TruncatedNormal, Constant\n",
    "\n",
    "'''\n",
    "#### Set truncated Gaussian distribution ####\n",
    "'''\n",
    "truncated_normal_initial = TruncatedNormal(std=.02)\n",
    "zero = Constant(value=0.)\n",
    "one = Constant(value=1.)\n",
    "\n",
    "\n",
    "## do nothing\n",
    "class Identity(nn.Layer):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(Identity, self).__init__()\n",
    "        \n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66e40ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#### Reshape the tensor while taking convolutional token embedding ####\n",
    "'''\n",
    "class Reshape(nn.Layer):\n",
    "    def __init__(self,string,h,w):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.string = string\n",
    "        self.h = h\n",
    "        self.w = w\n",
    "        \n",
    "        \n",
    "    def forward(self,inputs):\n",
    "\n",
    "        if self.string == 'b c h w -> b (h w) c':\n",
    "            N, C, H, W = inputs.shape\n",
    "            x = paddle.reshape(x=inputs, shape=(N, -1, self.h*self.w)).transpose((0, 2, 1))\n",
    "\n",
    "        if self.string == 'b (h w) c -> b c h w':\n",
    "            N, _, C = inputs.shape\n",
    "            x = paddle.reshape(x=inputs,shape=(N, self.h, self.w, -1)).transpose((0, 3, 1, 2))\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2eeeb14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#### Depth separable convolutional layer ####\n",
    "'''\n",
    "class DepSepConv2D(nn.Layer):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1):\n",
    "        \n",
    "        super(DepSepConv2D, self).__init__()\n",
    "\n",
    "        #depthwise Conv2D\n",
    "        self.depthwise = nn.Conv2D(in_channels=in_channels, out_channels=in_channels, kernel_size=kernel_size, \n",
    "                                   stride=stride, padding=padding, dilation=dilation, groups=in_channels)\n",
    "\n",
    "        self.bn = nn.BatchNorm(num_channels=in_channels)\n",
    "\n",
    "        #pointwise Conv2D\n",
    "        self.pointwise = nn.Conv2D(in_channels=in_channels, out_channels=out_channels, \n",
    "                                   kernel_size=1, stride=1, padding=0, dilation=1, groups=1)\n",
    "\n",
    "        \n",
    "    def forward(self,input):\n",
    "        x = self.depthwise(input)\n",
    "        x = self.bn(x)\n",
    "        x = self.pointwise(x)\n",
    "        \n",
    "        return  x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9320f243",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#### Reshape the tensor in the module of transformer if necessary. ####\n",
    "'''\n",
    "def reshape_in_transformer(x, string, l=0, w=0, h=0, **kwargs):\n",
    "    b, n , c = x.shape[:3]\n",
    "\n",
    "    if string == 'b n (h d) -> b h n d':\n",
    "        x = paddle.reshape(x=x,shape=(b, n, h, -1)).transpose((0, 2, 1, 3))\n",
    "\n",
    "    if string == 'b (l w) n -> b n l w':\n",
    "        x = paddle.reshape(x=x,shape=(b, l, w, -1)).transpose((0, 3, 1, 2))\n",
    "        \n",
    "    if string == 'b (h d) l w -> b h (l w) d':\n",
    "        b, h_d, l, w = x.shape\n",
    "        x = paddle.reshape(x=x,shape=(b, h, l*w, -1))\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daeb8772",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#### Multi-Heat Attention ####\n",
    "#### Here we use Depth Separable Convolutional Layer defined above, ####\n",
    "#### insteading of Linear Project in ViT. ####\n",
    "'''\n",
    "class ConAtt(nn.Layer):\n",
    "    def __init__(self, dim,img_size, heads=8, dim_head=64, \n",
    "                 kernel_size=3, q_stride=1, k_stride=1, v_stride=1, \n",
    "                 dropout=0., last_stage=False):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.last_stage = last_stage\n",
    "        self.img_size = img_size\n",
    "        inner_dim = dim_head * heads\n",
    "        project_out = not (heads==1 and dim_head==dim)\n",
    "\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** (-0.5)\n",
    "        pad = (kernel_size - q_stride) // 2\n",
    "        \n",
    "        ## using Depth Separable Convolution to reduce the parameters.\n",
    "        self.to_q = DepSepConv2D(in_channels=dim, out_channels=inner_dim, \n",
    "                                 kernel_size=kernel_size, stride=q_stride, padding=pad)\n",
    "        self.to_k = DepSepConv2D(in_channels=dim, out_channels=inner_dim, \n",
    "                                 kernel_size=kernel_size, stride=k_stride, padding=pad)\n",
    "        self.to_v = DepSepConv2D(in_channels=dim, out_channels=inner_dim, \n",
    "                                 kernel_size=kernel_size, stride=v_stride, padding=pad)\n",
    "\n",
    "        self.out = nn.Sequential(nn.Linear(in_features=inner_dim, out_features=dim), \n",
    "                                 nn.Dropout(dropout)) if project_out else Identity()\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        ## x shape: ([1, 3136, 64])\n",
    "        b, n, c, h = *x.shape, self.heads\n",
    "        \n",
    "        if self.last_stage:\n",
    "            cls_token = x[:, 0]\n",
    "            x = x[:, 1:]\n",
    "            ## class token for classification\n",
    "            cls_token = reshape_in_transformer(x=paddle.unsqueeze(cls_token, axis=1), \n",
    "                                               string='b n (h d) -> b h n d', h=h)\n",
    "\n",
    "        ## x shape: ([1, 64, 56, 56])\n",
    "        x = reshape_in_transformer(x=x, string='b (l w) n -> b n l w',\n",
    "                                   l=self.img_size, w=self.img_size)\n",
    "\n",
    "        ## q shape: ([1, 64, 56, 56])\n",
    "        q = self.to_q(x) \n",
    "        \n",
    "        ## q shape: ([1, 1, 3136, 64])\n",
    "        q = reshape_in_transformer(x=q, string='b (h d) l w -> b h (l w) d', h=h)\n",
    "\n",
    "        k = self.to_k(x)\n",
    "        k = reshape_in_transformer(x=k, string='b (h d) l w -> b h (l w) d', h=h)\n",
    "\n",
    "        v = self.to_v(x)\n",
    "        v = reshape_in_transformer(x=v, string='b (h d) l w -> b h (l w) d', h=h)\n",
    "\n",
    "        if self.last_stage:\n",
    "            q = paddle.concat((cls_token, q), axis=2)\n",
    "            v = paddle.concat((cls_token, v), axis=2)\n",
    "            k = paddle.concat((cls_token, k), axis=2)\n",
    "\n",
    "\n",
    "        ## calculate final attention\n",
    "        attention = (q.matmul(k.transpose((0,1,3,2)))) * self.scale\n",
    "\n",
    "        ## take softmax\n",
    "        attention = func.softmax(attention, axis=-1)\n",
    "\n",
    "        ## matmul v\n",
    "        out = (attention.matmul(v)).transpose((0, 2, 1, 3)).reshape((b, n, c))\n",
    "\n",
    "        #linear project\n",
    "        out = self.out(out)\n",
    "        \n",
    "        return  out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c49e827",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#### Residual skip connection in transformer module ####\n",
    "'''\n",
    "class Residual(nn.Layer):\n",
    "    def __init__(self, fn):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.fn = fn\n",
    "\n",
    "        \n",
    "    def forward(self, inputs, **kwargs):\n",
    "        x = self.fn(inputs, **kwargs)\n",
    "        \n",
    "        return (x + inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "853d4fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#### Add Layer Normalization ####\n",
    "'''\n",
    "class LayerNorm(nn.Layer):\n",
    "    def __init__(self, dim, fn):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.fn = fn\n",
    "        \n",
    "        \n",
    "    def forward(self, inputs, **kwargs):\n",
    "        \n",
    "        return self.fn(self.norm(inputs), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1822a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#### MLP Layer ####\n",
    "'''\n",
    "class FeedForward(nn.Layer):\n",
    "    def __init__(self, dim, hidden_dim, dropout=0.):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.neu_net = nn.Sequential(nn.Linear(in_features=dim, out_features=hidden_dim),\n",
    "                                     nn.GELU(),\n",
    "                                     nn.Dropout(dropout),\n",
    "                                     nn.Linear(in_features=hidden_dim, out_features=dim),\n",
    "                                     nn.Dropout(dropout))\n",
    "        \n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        \n",
    "        return self.neu_net(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65c7b807",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#### Defination of Transformer Layer ####\n",
    "'''\n",
    "class Transformer(nn.Layer):\n",
    "    def __init__(self, dim, img_size, depth, heads, dim_head, mlp_dim, dropout=0., last_stage=False):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers = nn.LayerList([nn.LayerList(\n",
    "            [LayerNorm(dim=dim, fn=ConAtt(dim,img_size, heads=heads, dim_head=dim_head, \n",
    "                                          dropout=dropout, last_stage=last_stage)),\n",
    "             LayerNorm(dim=dim, fn=FeedForward(dim=dim, hidden_dim=mlp_dim, dropout=dropout))\n",
    "            ]) for _ in range(depth)\n",
    "        ])\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for attention, feed_forward in self.layers:\n",
    "            x = attention(x) + x\n",
    "            x = feed_forward(x) + x\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f3c0372",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#### Final CvT ####\n",
    "'''\n",
    "class CvT(nn.Layer):\n",
    "    def __init__(self, image_size, in_channels, num_classes, \n",
    "                 dim=64, kernels=[7, 3, 3], strides=[4, 2, 2],\n",
    "                 heads=[1, 3, 6], depth=[1, 2, 10], \n",
    "                 pool='cls', dropout=0., emb_dropout=0., scale_dim=4):\n",
    "        \n",
    "        super().__init__()\n",
    "\n",
    "        ## pool type must be either cls or mean pooling\n",
    "        self.pool = pool\n",
    "        self.dim = dim\n",
    "        \n",
    "        ## stage 1\n",
    "        self.stage1_conv_embed = nn.Sequential(nn.Conv2D(in_channels=in_channels, out_channels=dim, \n",
    "                                                         kernel_size=kernels[0], stride=strides[0], \n",
    "                                                         padding=2),\n",
    "                                               Reshape('b c h w -> b (h w) c', \n",
    "                                                       h=image_size//4, w=image_size//4),\n",
    "                                               nn.LayerNorm(dim))\n",
    "        \n",
    "        self.stage1_transformer = nn.Sequential(Transformer(dim=dim, img_size=image_size//4, \n",
    "                                                            depth=depth[0], heads=heads[0], \n",
    "                                                            dim_head=self.dim, mlp_dim=dim*scale_dim, \n",
    "                                                            dropout=dropout), \n",
    "                                                Reshape(string='b (h w) c -> b c h w', \n",
    "                                                        h=image_size//4, w=image_size//4))\n",
    "\n",
    "        ## stage 2\n",
    "        in_channels = dim\n",
    "        scale = heads[1] // heads[0]\n",
    "        dim = scale * dim\n",
    "        \n",
    "        self.stage2_conv_embed = nn.Sequential(nn.Conv2D(in_channels=in_channels, out_channels=dim, \n",
    "                                                         kernel_size=kernels[1], stride=strides[1], \n",
    "                                                         padding=1),\n",
    "                                               Reshape(string='b c h w -> b (h w) c',\n",
    "                                                        h=image_size//8, w=image_size//8), \n",
    "                                               nn.LayerNorm(dim))\n",
    "        \n",
    "        self.stage2_transformer = nn.Sequential(Transformer(dim=dim, img_size=image_size//8, \n",
    "                                                            depth=depth[1], heads=heads[1], \n",
    "                                                            dim_head=self.dim, mlp_dim=dim*scale_dim, \n",
    "                                                            dropout=dropout), \n",
    "                                                Reshape(string='b (h w) c -> b c h w', \n",
    "                                                         h=image_size//8, w=image_size//8))\n",
    "\n",
    "        ## stage 3\n",
    "        in_channels = dim\n",
    "        scale = heads[2] // heads[1]\n",
    "        dim = scale * dim\n",
    "        \n",
    "        self.stage3_conv_embed = nn.Sequential(nn.Conv2D(in_channels=in_channels, out_channels=dim, \n",
    "                                                         kernel_size=kernels[2], stride=strides[2], \n",
    "                                                         padding=1),\n",
    "                                               Reshape(string='b c h w -> b (h w) c', \n",
    "                                                        h=image_size//16, w=image_size//16),\n",
    "                                               nn.LayerNorm(dim))\n",
    "        \n",
    "        self.stage3_transformer = nn.Sequential(Transformer(dim=dim, img_size=image_size//16, \n",
    "                                                            depth=depth[2], heads=heads[2], \n",
    "                                                            dim_head=self.dim, mlp_dim=dim*scale_dim, \n",
    "                                                            dropout=dropout, last_stage=True))\n",
    "\n",
    "        ## class token\n",
    "        self.cls_token = self.create_parameter(shape=(1, 1, dim), default_initializer=zero)\n",
    "        \n",
    "        self.add_parameter(\"cls_token\", self.cls_token)\n",
    "\n",
    "        self.dropout_large = nn.Dropout(emb_dropout)\n",
    "\n",
    "        self.mlp_head = nn.Sequential(nn.LayerNorm(dim), nn.Linear(in_features=dim, \n",
    "                                                                   out_features=num_classes))\n",
    "\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.stage1_conv_embed(inputs)\n",
    "        x = self.stage1_transformer(x)\n",
    "\n",
    "        x = self.stage2_conv_embed(x)\n",
    "        x = self.stage2_transformer(x)\n",
    "\n",
    "        x = self.stage3_conv_embed(x)\n",
    "\n",
    "        b, n, _ = x.shape\n",
    "        \n",
    "        cls_tokens = self.cls_token.expand((b, -1, -1))\n",
    "        \n",
    "        x = paddle.concat((cls_tokens, x), axis=1)\n",
    "\n",
    "        x = self.stage3_transformer(x)\n",
    "\n",
    "        x = paddle.mean(x, axis=1) if self.pool == 'mean' else x[:,0]\n",
    "\n",
    "        x = self.mlp_head(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "add79fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of output: [1, 4]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "###############\n",
    "#### Check ####\n",
    "###############\n",
    "'''\n",
    "def main():\n",
    "    model = CvT(image_size=512, in_channels=1, num_classes=4)\n",
    "\n",
    "#     paddle.summary(model,input_size=(1, 1, 512, 512))\n",
    "\n",
    "    out = model(paddle.randn(shape=(1, 1, 512, 512)))\n",
    "\n",
    "    print(f'Shape of output: {out.shape}')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9586ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "addresses: type <class 'pandas.core.series.Series'>,  shape (6334,)\n",
      "labels: type <class 'numpy.ndarray'>,  shape (6334, 4)\n",
      "\n",
      "x_train shape: (5067,), x_train type: <class 'pandas.core.series.Series'>\n",
      "\n",
      "y_train shape: (5067, 4), y_train type: <class 'numpy.ndarray'>\n",
      "\n",
      "x_test shape: (1267,), x_test type: <class 'pandas.core.series.Series'>\n",
      "\n",
      "y_test shape: (1267, 4), y_test type: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "'''\n",
    "Covid19-Deteciton Data Split\n",
    "'''\n",
    "show_data = pd.read_csv(os.path.join(f\"..\", f\"covid19-detection data\", f\"train.csv\"))\n",
    "# show_data.head()\n",
    "\n",
    "show_data[\"filepath\"] = [os.path.join(f\"covid19-detection data\", f\"train\", f\"{image_id}.jpg\") \n",
    "                for image_id in show_data[\"image_id\"]]\n",
    "\n",
    "\n",
    "images_addresses = show_data[\"filepath\"]\n",
    "images_labels = np.array(show_data[[\"Negative for Pneumonia\", \"Typical Appearance\", \n",
    "                             \"Indeterminate Appearance\", \"Atypical Appearance\"]])\n",
    "\n",
    "print(f\"addresses: type {type(images_addresses)},  shape {images_addresses.shape}\")\n",
    "print(f\"labels: type {type(images_labels)},  shape {images_labels.shape}\")\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(images_addresses, images_labels, \n",
    "                                                    test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"\\nx_train shape: {x_train.shape}, x_train type: {type(x_train)}\")\n",
    "print(f\"\\ny_train shape: {y_train.shape}, y_train type: {type(y_train)}\")\n",
    "print(f\"\\nx_test shape: {x_test.shape}, x_test type: {type(x_test)}\")\n",
    "print(f\"\\ny_test shape: {y_test.shape}, y_test type: {type(y_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "745680a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "##########  Dataset and DataLoader  ##########\n",
    "'''\n",
    "\n",
    "import paddle.distributed as distribute\n",
    "\n",
    "from paddle.io import Dataset, DataLoader, DistributedBatchSampler\n",
    "\n",
    "\n",
    "class ProjectDataset(Dataset):\n",
    "    def __init__(self, x_train, y_train):\n",
    "        super().__init__()\n",
    "        self.data = np.array(x_train)\n",
    "        self.label = y_train\n",
    "\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return paddle.to_tensor(self.data[idx]), paddle.to_tensor(self.label[idx])\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data) #len(self.label)\n",
    "\n",
    "    \n",
    "def get_dataset():\n",
    "    dataset = ProjectDataset()\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "\n",
    "def get_dataloader(dataset, batch_size):\n",
    "    sampler = DistributedBatchSampler(dataset, batch_size=batch_size, shuffle=True)\n",
    "    dataloader = DataLoader(dataset, batch_sampler=sampler)\n",
    "    \n",
    "    return dataloader\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    model = CvT(image_size=512, in_channels=1, num_classes=4)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def processor(*args):\n",
    "    dataset = args[0]\n",
    "    dataloader = get_dataloader(dataset, batch_size=64)\n",
    "    distribute.init_parallel_env()\n",
    "    world_size = dist.get_world_size()\n",
    "    rank = dist.get_rank()\n",
    "\n",
    "    model = build_model()\n",
    "    model = paddle.DataParallel(model)\n",
    "    print(f\"local_rank: {rank}\")\n",
    "\n",
    "    tensor_list = []\n",
    "    for data in dataloader:\n",
    "        image = data[0]\n",
    "        label = data[1]\n",
    "\n",
    "        output = model(image)\n",
    "        output = output.argmax(1)\n",
    "        print(f\"\\nlocal_rank {rank}: {image.cpu().numpy()}, \\\n",
    "                \\nlabel: {image.cpu().numpy()}, \\\n",
    "                \\nout: {output.cpu().numpy()}\")\n",
    "\n",
    "        distribute.all_gather(tensor_list, output)\n",
    "        if rank == 0:\n",
    "            print(f\"local_rank {rank}: tensor {tensor_list}\")\n",
    "        break\n",
    "\n",
    "        \n",
    "def main():\n",
    "    dataset = get_dataset()\n",
    "    distribute.spawn(processor, args=(dataset, ), nprocs=4)\n",
    "\n",
    "    \n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f32f44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
